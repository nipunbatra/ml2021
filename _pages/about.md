---
layout: about
permalink: /
title: Machine Learning Spring 2020
description: ES 654
---


*** Under repair ***

*   Instructor: Nipun Batra (nipun.batra@iitgn.ac.in)
*   Teaching Assistants: Indradeep (indra.mastan@iitgn.ac.in), Sudhakar (sudhakar.kumawat@iitgn.ac.in ), Supratim (supratim.shit@iitgn.ac.in), Shubham (shubam.singh@iitgn.ac.in)
*   Course Timings: Tue and Friday (3:30 to 5 PM in 1/101)  
    Office hours: Monday (12 Noon to 1): Please try to stick to this time unless it is an emergency

* * *

Pre-requisites:

*   Good experience in Python programming
*   Probability
*   Linear Algebra

Course preparation: Students are encouraged to study some of the following to refresh their understanding of some of the prerequisities before the course formally begins.  

*   First four chapters of the [Python Data Science handbook](https://jakevdp.github.io/PythonDataScienceHandbook/)
*   [Some material on Linear Algebra](https://machinelearningmastery.com/linear-algebra-machine-learning/)
*   [Khan academy course on Stats and Probability](https://www.khanacademy.org/math/statistics-probability)

* * *

Reference textbooks:

1.  Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. [An Introduction to Statistical Learning with Applications in R](http://www-bcf.usc.edu/~gareth/ISL/)
2.  Christopher Bishop. Pattern Recognition and Machine Learning. Springer, 2006.[\[Freely available online\]](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)
3.  Friedman J, Hastie T, Tibshirani R. The elements of statistical learning. New York, NY, USA:: Springer series in statistics; 2001.[\[Freely available online\]](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)
4.  Duda RO, Hart PE, Stork DG. Pattern classification. John Wiley & Sons; 2012 Nov 9.
5.  Mitchell TM. Machine learning. 1997. Burr Ridge, IL: McGraw Hill. 1997;45(37):870-7.
6.  Murphy, K. Machine Learning: A Probabilistic Perspective. MIT Press
7.  Goodfellow I, Bengio Y, Courville A, Bengio Y. Deep learning. Cambridge: MIT press; 2016 Nov 18.[\[Freely available online\]](https://www.deeplearningbook.org/)

* * *

**Grading policy:**

*   Project (in groups of 4 or less) [(Some ideas from instructors)](https://docs.google.com/document/d/1sM-BdF7tCofvXwsvB22Tv5ve8JQAEwA5kh705uzsNns), and [some ideas from a Stanford ML course](http://cs229.stanford.edu/proj2017/) : 40%

*   Project proposal report (due Jan 20) : 5%
*   Phase-I presentation (week of Feb 10) : 5%
*   Phase-II presentation (week of March 15) : 5%
*   Final project 3 minute madness (week of April 20) \[See 3MT for inspiration\] : 5%
*   Final project demo and poster (week of April 20) : 15%
*   Final report (due April 22) : 5%

*   3 Surprise quizzes worth 3% each, best 2/3 are recorded for grade : 6%

*   Quiz 1 will be held before or on 15th Jan
*   Quiz 2 will be held before or

*   End semester : 10%
*   [Paper presentation](https://docs.google.com/spreadsheets/d/19X7uj0evg1aCV_iVnrrZjquG6jr5Qdpg06TqvNiPvTE/edit#gid=0) \[[Slides template](https://docs.google.com/presentation/d/1IOb5osggH6rGzJmS3f7drlGJAk3WzhmCpnDHecOzoPI/edit#slide=id.g4d46f3c2cc_0_55)\]\[3 people argue for each paper. One person summarises the paper, second person acts as an advocate representing the paper; and the third person is the devil's advocate convincing the jury that paper has flaws\] : 4%
*   Kaggle competition : 4% \[done individually, due sometime early April\]
*   Machine Learning demo (like [this](http://stanford.edu/class/ee103/visualizations/kmeans/kmeans.html) or [this](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/) or [this](https://www.saedsayad.com/flash/SLR.html) or [this](https://cs.stanford.edu/people/karpathy/svmjs/demo/demoforest.html)) \[Same team as project\]\[due 30th March \] : 4%
*   8 Programming Homework Assignments (50% credit for late submission (upto 1 day for 1st assignment and 2 for others)) \[**NB - A subset of these will have an associated viva**\] : 32%
*   Bonus marks - 10 marks if you get into Master level on Kaggle or 5 marks if you get into Expert level on Kaggle


* * *

Some other ML courses

1.  [NPTEL course by Balaram Ravindran](https://www.youtube.com/watch?v=r4sgKrRL2Ys&list=PL1xHD4vteKYVpaIiy295pg6_SY5qznc77)
2.  [CMU course by Tom Mitchell and Maria-Florina Balcan](http://www.cs.cmu.edu/~ninamf/courses/601sp15/lectures.shtml)
3.  [Coursera ML course by Andrew Ng](https://www.coursera.org/learn/machine-learning)
4.  [FAST.ai course on ML](https://course.fast.ai/ml)
5.  [Practical deep learning for coders by FAST.ai](https://course.fast.ai/index.html)
6.  [Course by Alex Ihler, UCI](http://sli.ics.uci.edu/Classes/2015W-273a)

